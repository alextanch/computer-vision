{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4eff6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colab: False\n"
     ]
    }
   ],
   "source": [
    "# запускаем в colab или локально?\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab = True\n",
    "except ImportError:\n",
    "    colab = False\n",
    "\n",
    "print(f\"colab: {colab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6965c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка необходимых пакетов в colab\n",
    "if colab:\n",
    "    ! pip install rootutils -q\n",
    "    ! pip install torchmetrics -q\n",
    "    ! pip install torchinfo -q\n",
    "    ! pip install lightning -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c0a22da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working directory: /Users/alex/computer-vision\n"
     ]
    }
   ],
   "source": [
    "# монтирование google диска и установка\n",
    "# рабочей директории в `computer-vision`\n",
    "\n",
    "import os\n",
    "import rootutils\n",
    "\n",
    "root = rootutils.setup_root(\".\", indicator=\"homeworks\", pythonpath=True)\n",
    "\n",
    "if colab:\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "    os.chdir(\"drive/MyDrive/computer-vision\")\n",
    "else:\n",
    "    os.chdir(root)\n",
    "\n",
    "print(f\"working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97f5566b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: /Users/alex/computer-vision/data\n"
     ]
    }
   ],
   "source": [
    "# создание директории для данных\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "if colab:\n",
    "    DATA_DIR = Path(\"/content/data\")\n",
    "else:\n",
    "    DATA_DIR = root / \"data\"\n",
    "\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8dd3fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройки для matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"retina\"\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b7bf7",
   "metadata": {},
   "source": [
    "## **Полносвязные нейронные сети. Методы регуляризации**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f6f60",
   "metadata": {},
   "source": [
    "### **Полносвязные нейронные сети**\n",
    "\n",
    "**Полносвязные нейронные сети** (Fully Connected Neural Networks, FCNN).\n",
    "\n",
    "Другое название - **многослойный перцептрон** (Multilayer Perceptron, MLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a686dec",
   "metadata": {},
   "source": [
    "#### **Пример полносвязной сети**\n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "        <img src=\"figs/02/fcnn.jpg\" width=\"600px\"/>\n",
    "    </figure>\n",
    "</center>\n",
    "\n",
    "- У этой сети один входной слой, один выходной слой и три скрытых слоя.\n",
    "\n",
    "- Параметры нейронной сети \n",
    "    $$\n",
    "        \\mathbf{w} = \\left\\{\n",
    "            \\boldsymbol{\\beta}_0,\\boldsymbol{\\Omega}_0,\n",
    "            \\boldsymbol{\\beta}_1,\\boldsymbol{\\Omega}_1,\n",
    "            \\boldsymbol{\\beta}_2,\\boldsymbol{\\Omega}_2,\n",
    "            \\boldsymbol{\\beta}_3,\\boldsymbol{\\Omega}_3\n",
    "        \\right\\}\n",
    "    $$\n",
    "    Число параметров равно:\n",
    "    $$\n",
    "        (D_1\\cdot D_i + D_1) + (D_2\\cdot D_1 + D_2) + (D_3\\cdot D_2 + D_3) + (D_0\\cdot D_3 + D_0) = 43\n",
    "    $$\n",
    "\n",
    "- Вычисления слоев нейронной сети:\n",
    "    $$\n",
    "        \\mathbf{h}_1 = \\mathbf{a}\\left[\\boldsymbol{\\beta}_0 + \\mathbf{\\Omega}_0 \\mathbf{x}\\right]\n",
    "    $$\n",
    "    $$\n",
    "        \\mathbf{h}_2 = \\mathbf{a}\\left[\\boldsymbol{\\beta}_1 + \\mathbf{\\Omega}_1 \\mathbf{h}_1\\right]\n",
    "    $$\n",
    "    $$\n",
    "        \\mathbf{h}_3 = \\mathbf{a}\\left[\\boldsymbol{\\beta}_2 + \\mathbf{\\Omega}_2 \\mathbf{h}_2\\right]\n",
    "    $$\n",
    "    $$\n",
    "        \\mathbf{y} = \\boldsymbol{\\beta}_3 + \\mathbf{\\Omega}_3 \\mathbf{h}_3\n",
    "    $$\n",
    "\n",
    "    где $\\mathbf{a}$ - функция активации, обычно это $\\mathrm{ReLU}$ (Rectified Linear Unit):\n",
    "    <center>\n",
    "        <figure>\n",
    "            <img src=\"figs/02/relu.png\" width=\"200px\"/>\n",
    "        </figure>\n",
    "    </center>\n",
    "\n",
    "    $$\n",
    "        a[z] = \\mathrm{ReLU}[z] =\n",
    "        \\begin{cases}\n",
    "            0 & z < 0\\\\\n",
    "            z & z \\geqslant 0\n",
    "        \\end{cases}\n",
    "    $$\n",
    "\n",
    "- Сеть называется **полносвязной**, поскольку каждый элемент (node) связан со всеми предыдущими элементами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca713d",
   "metadata": {},
   "source": [
    "#### **Полносвязные нейронной сети в PyTorch**\n",
    "\n",
    "Напишем класс для нашей полносвязной нейронной сети в PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20547840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, Di=3, D1=4, D2=2, D3=3, Do=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin1 = nn.Linear(Di, D1)\n",
    "        self.lin2 = nn.Linear(D1, D2)\n",
    "        self.lin3 = nn.Linear(D2, D3)\n",
    "        self.lin4 = nn.Linear(D3, Do)\n",
    "\n",
    "        self.act = nn.ReLU() \n",
    "         \n",
    "    def forward(self, x):\n",
    "        h1 = self.act(self.lin1(x))\n",
    "        h2 = self.act(self.lin2(h1))\n",
    "        h3 = self.act(self.lin3(h2))\n",
    "        \n",
    "        y = self.lin4(h3)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64444c15",
   "metadata": {},
   "source": [
    "Протестируем работу сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ee3aa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([5, 3])\n",
      "\n",
      "x: tensor([[0.4963, 0.6110, 0.3511],\n",
      "        [0.7422, 0.2820, 0.5964],\n",
      "        [0.4928, 0.4250, 0.7450],\n",
      "        [0.1069, 0.0778, 0.2699],\n",
      "        [0.7057, 0.7139, 0.4999]])\n",
      "\n",
      "y.shape: torch.Size([5, 2])\n",
      "\n",
      "y: tensor([[-0.8796,  0.0899],\n",
      "        [-0.8828,  0.0907],\n",
      "        [-0.9017,  0.0812],\n",
      "        [-0.8735,  0.0977],\n",
      "        [-0.8852,  0.0877]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# модель сети\n",
    "model = Net()\n",
    "\n",
    "# батч размера 5 из случайных чисел\n",
    "x = torch.rand((5, 3))\n",
    "\n",
    "# forward pass\n",
    "y = model(x)\n",
    "\n",
    "print(f\"x.shape: {x.shape}\")\n",
    "print(f\"\\nx: {x}\")\n",
    "print(f\"\\ny.shape: {y.shape}\")\n",
    "print(f\"\\ny: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751c466",
   "metadata": {},
   "source": [
    "Выведем информацию о архитектуре сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be3dfac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Net                                      [5, 2]                    --\n",
      "├─Linear: 1-1                            [5, 4]                    16\n",
      "├─ReLU: 1-2                              [5, 4]                    --\n",
      "├─Linear: 1-3                            [5, 2]                    10\n",
      "├─ReLU: 1-4                              [5, 2]                    --\n",
      "├─Linear: 1-5                            [5, 3]                    9\n",
      "├─ReLU: 1-6                              [5, 3]                    --\n",
      "├─Linear: 1-7                            [5, 2]                    8\n",
      "==========================================================================================\n",
      "Total params: 43\n",
      "Trainable params: 43\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "print(torchinfo.summary(model, input_size=x.shape, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1177d6c",
   "metadata": {},
   "source": [
    "Можно написать более компактную реализацию с помощью `torch.nn.Sequential`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8191bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Net                                      [5, 2]                    --\n",
      "├─Sequential: 1-1                        [5, 2]                    --\n",
      "│    └─Linear: 2-1                       [5, 4]                    16\n",
      "│    └─ReLU: 2-2                         [5, 4]                    --\n",
      "│    └─Linear: 2-3                       [5, 2]                    10\n",
      "│    └─ReLU: 2-4                         [5, 2]                    --\n",
      "│    └─Linear: 2-5                       [5, 3]                    9\n",
      "│    └─ReLU: 2-6                         [5, 3]                    --\n",
      "│    └─Linear: 2-7                       [5, 2]                    8\n",
      "==========================================================================================\n",
      "Total params: 43\n",
      "Trainable params: 43\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, Di=3, D1=4, D2=2, D3=3, Do=2):\n",
    "        super().__init__()\n",
    "\n",
    "        act = nn.ReLU()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(Di, D1),\n",
    "            act,\n",
    "            nn.Linear(D1, D2),\n",
    "            act,\n",
    "            nn.Linear(D2, D3),\n",
    "            act,\n",
    "            nn.Linear(D3, Do),\n",
    "        )\n",
    "         \n",
    "    def forward(self, x):\n",
    "        y = self.layers(x)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    model = Net()\n",
    "\n",
    "    print(torchinfo.summary(model, input_size=x.shape, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffc6f4",
   "metadata": {},
   "source": [
    "### **Классификация изображений Fashion-MNIST**\n",
    "\n",
    "<center>\n",
    "        <figure>\n",
    "            <img src=\"figs/02/fashion_mnist.jpg\" width=\"600px\"/>\n",
    "        </figure>\n",
    "    </center>\n",
    "Обучим полносвязную нейронную сеть классифицировать изображения из датасета Fashion-MNIST:\n",
    "\n",
    "- Размер изображений: 28x28 пикселей\n",
    "\n",
    "- Цветовое пространство: grayscale\n",
    "\n",
    "- Количество классов: 10 (одежда)\n",
    "\n",
    "- Размер набора данных: 60 000 обучающих и 10 000 тестовых изображений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b63d310",
   "metadata": {},
   "source": [
    "В torchvision есть класс `torchvision.datasets.FashionMNIST` для работы с этим датасетом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec003db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 60000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1. Define transformations: Convert images to PyTorch tensors\n",
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "             \n",
    "# 2. Load the Fashion-MNIST datasets (downloads if not present)\n",
    "train_dataset = FashionMNIST(\n",
    "    root=DATA_DIR, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = FashionMNIST(\n",
    "    root=DATA_DIR, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 3. Define the class names\n",
    "class_names = {\n",
    "    0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat',\n",
    "    5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'\n",
    "}\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05de898",
   "metadata": {},
   "source": [
    "Посмотрим на один из сэмплов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e3cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([1, 28, 28])\n",
      "label: 3\n",
      "class name: Dress\n"
     ]
    }
   ],
   "source": [
    "# x - tensor\n",
    "# y - int\n",
    "x, y = train_dataset[2026]\n",
    "\n",
    "class_name = class_names[y]\n",
    "\n",
    "print(f\"x.shape: {x.shape}\")\n",
    "print(f\"label: {y}\")\n",
    "print(f\"class name: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "207c92c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 272,
       "width": 250
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# де-нормализация изображения\n",
    "image = (255 * x.squeeze()).numpy().astype(np.uint8)\n",
    "\n",
    "# построение изображения\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.title(f\"class name: {class_name}\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866b94a",
   "metadata": {},
   "source": [
    "Мы напишем собственную реализацию `torch.utils.data.Dataset` для Fashion-MNIST.\n",
    "\n",
    "Загрузим и распакуем изображения с google диска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1c52194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alex/computer-vision/data/fashion-mnist.zip downloading...\n",
      "Extracting...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from src.utils import download_and_extract\n",
    "\n",
    "download_and_extract(\"1KpBql_Rpc1dtBSwFTT7UZdNLUoDde6YQ\", \"fashion-mnist.zip\", DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af684e",
   "metadata": {},
   "source": [
    "Напишем класс для итерации по данным по одному сэмплу (x, y):\n",
    "\n",
    "- x - изображение 28 x 28\n",
    "\n",
    "- y - метка класса 0, 1, 2, ..., 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd4d3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DataSet(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        super().__init__()\n",
    "\n",
    "        self.files = list(Path(data_dir).glob(\"**/*.png\"))\n",
    "        self.labels = [int(f.parent.name) for f in self.files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(self.files[index], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # нормализация изображения в диапазон [0, 1]\n",
    "        x = image.astype(np.float32) / 255\n",
    "\n",
    "        # преобразование размера\n",
    "        # 28 x 28 в 1 x 28 x 28\n",
    "        x = x[None]\n",
    "\n",
    "        # метка класса \n",
    "        y = self.labels[index]\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33e7a3",
   "metadata": {},
   "source": [
    "Создадим датасеты для обучения и тестирования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4353166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 60000\n",
      "test_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSet(DATA_DIR / \"fashion-mnist/train\")\n",
    "test_dataset = DataSet(DATA_DIR / \"fashion-mnist/test\")\n",
    "\n",
    "# число изображений в датасетах\n",
    "print(f\"dataset size: {len(dataset)}\")\n",
    "print(f\"test_dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84333b",
   "metadata": {},
   "source": [
    "Посмотрим на один из сэмплов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "126ac9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (1, 28, 28)\n",
      "y: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 272,
       "width": 250
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x - numpy массив\n",
    "# y - int\n",
    "x, y = dataset[2026]\n",
    "\n",
    "# имя класса\n",
    "class_name = class_names[y]\n",
    "\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y: {y}\")\n",
    "\n",
    "# де-нормализация изображения\n",
    "image = (255 * x[0]).astype(np.uint8)\n",
    "\n",
    "# построение изображения\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.title(f\"class: {class_name}\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb303fa9",
   "metadata": {},
   "source": [
    "Разделим `dataset` на датасеты для обучения и валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "905c8eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size: 50000\n",
      "valid_dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_dataset, valid_dataset = random_split(\n",
    "    dataset,\n",
    "    [50_000, 10_000]\n",
    ")\n",
    "\n",
    "print(f\"train_dataset size: {len(train_dataset)}\")\n",
    "print(f\"valid_dataset size: {len(valid_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df337bf6",
   "metadata": {},
   "source": [
    "Создадим загрузчики батчей для обучения и валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23b5fca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader size: 48\n",
      "valid_loader size: 10\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,   # датасет\n",
    "    batch_size=1024, # размер батча\n",
    "    num_workers=0,   # число процессов для формирования батчей\n",
    "    shuffle=True,    # перемешивать датасет в конце каждой эпохи\n",
    "    drop_last=True   # выбрасывать последний неполный батч в эпохе\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1024,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# число батчей\n",
    "print(f\"train_loader size: {len(train_loader)}\")\n",
    "print(f\"valid_loader size: {len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212234f",
   "metadata": {},
   "source": [
    "Сгенерируем один батч из данных для обучения: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55b3e1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([1024, 1, 28, 28])\n",
      "y shape: torch.Size([1024])\n",
      "\n",
      "x.min(): 0.0\n",
      "x.max(): 1.0\n"
     ]
    }
   ],
   "source": [
    "# для изображений размер батча должен\n",
    "# иметь вид B x C x H x W\n",
    "# (размер батча) x (число цветовых каналов) x (высота изображения) x (ширина изображения)\n",
    "\n",
    "# выборка случайного батча данных из датасета\n",
    "# x, y - это тензоры\n",
    "x, y = next(iter(train_loader))\n",
    "\n",
    "# приведение к нужному типу данных\n",
    "x = x.float()\n",
    "y = y.long()\n",
    "\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y shape: {y.shape}\\n\")\n",
    "\n",
    "print(f\"x.min(): {x.min()}\")\n",
    "print(f\"x.max(): {x.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ccbac",
   "metadata": {},
   "source": [
    "Создадим полносвязную нейронную сеть для классификации с двумя скрытыми слоями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4559ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(nn.Module):\n",
    "    def __init__(self, Di=28*28, D1=392, D2=196, D3=98, Do=10):\n",
    "        super().__init__()\n",
    "\n",
    "        act = nn.ReLU()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(Di, D1),\n",
    "            act,\n",
    "            nn.Linear(D1, D2),\n",
    "            act,\n",
    "            nn.Linear(D2, D3),\n",
    "            act,\n",
    "            nn.Linear(D3, Do),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # преобразуем размер \n",
    "        # B x 1 x 28 x 28 -> B x (28 * 28)\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        \n",
    "        y = self.layers(x)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a036718",
   "metadata": {},
   "source": [
    "Протестируем модель сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8017c425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([1024, 1, 28, 28])\n",
      "y_hat shape: torch.Size([1024, 10])\n"
     ]
    }
   ],
   "source": [
    "model = Classification()\n",
    "\n",
    "x, y = next(iter(valid_loader))\n",
    "\n",
    "y_hat = model(x)\n",
    "\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y_hat shape: {y_hat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a58a0e8",
   "metadata": {},
   "source": [
    "Выведем архитектуру модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ee645d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Classification                           [1024, 10]                --\n",
      "├─Sequential: 1-1                        [1024, 10]                --\n",
      "│    └─Linear: 2-1                       [1024, 392]               307,720\n",
      "│    └─ReLU: 2-2                         [1024, 392]               --\n",
      "│    └─Linear: 2-3                       [1024, 196]               77,028\n",
      "│    └─ReLU: 2-4                         [1024, 196]               --\n",
      "│    └─Linear: 2-5                       [1024, 98]                19,306\n",
      "│    └─ReLU: 2-6                         [1024, 98]                --\n",
      "│    └─Linear: 2-7                       [1024, 10]                990\n",
      "==========================================================================================\n",
      "Total params: 405,044\n",
      "Trainable params: 405,044\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 414.77\n",
      "==========================================================================================\n",
      "Input size (MB): 3.21\n",
      "Forward/backward pass size (MB): 5.70\n",
      "Params size (MB): 1.62\n",
      "Estimated Total Size (MB): 10.53\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(torchinfo.summary(model, input_size=x.shape, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892b81a",
   "metadata": {},
   "source": [
    "Функция потерь для задачи мультиклассовой классификации - средняя кросс-энтропия на батче (Cross Entropy):\n",
    "$$\n",
    "    \\mathbf{CE} = \n",
    "    -\\frac{1}{|\\mathcal{I}_t|}\n",
    "    \\sum_{i\\in\\mathcal{I}_t}\\mathbf{p}_i\\cdot\\ln \\widehat{\\mathbf{p}}_i\n",
    "$$\n",
    "где $\\mathbf{p}_i$ - one-hot вектор истинных вероятностей изображения с номером $i$:\n",
    "$$\n",
    "   \\mathbf{p}_i = (0\\,,0\\,,\\ldots\\,,1\\,,0\\,,\\ldots\\,,0)\n",
    "$$ \n",
    "$\\widehat{\\mathbf{p}}_i$ - вектор предсказанных моделью вероятностей изображения с номером $i$:\n",
    "$$\n",
    "    \\widehat{\\mathbf{p}}_i = \\mathrm{softmax}[\\widehat{\\mathbf{y}}_i] = \n",
    "    \\frac{\\exp[\\widehat{\\mathbf{y}}_i]}{\\sum\\limits_j \\exp[\\widehat{y}_{ij}]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5668e73",
   "metadata": {},
   "source": [
    "Загрузчик данных возвращает $\\left\\{\\mathbf{y}_i\\right\\}_{i\\in\\mathcal{I}_t}$.\n",
    "\n",
    "Модель возвращает $\\left\\{\\widehat{\\mathbf{y}}_i\\right\\}_{i\\in\\mathcal{I}_t}$.\n",
    "\n",
    "Все необходимые преобразования в вероятности происходят в классе `torch.nn.CrossEntropyLoss()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9feca23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value = 2.308345079421997\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "\n",
    "y_hat = model(x.float())\n",
    "\n",
    "# вычисление loss функции по предсказанию `y_hat` и реальному `y`\n",
    "# вычисления softmax и one-hot encoding `y` реализовано в `loss_fn` \n",
    "loss = loss_fn(y_hat, y)\n",
    "\n",
    "print(f\"loss value = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2d321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
