{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4eff6d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T15:58:11.868097Z",
     "start_time": "2026-01-19T15:58:11.769167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colab: False\n"
     ]
    }
   ],
   "source": [
    "# –∑–∞–ø—É—Å–∫–∞–µ–º –≤ colab –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ?\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab = True\n",
    "except ImportError:\n",
    "    colab = False\n",
    "\n",
    "print(f\"colab: {colab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6965c74a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T15:58:13.943566Z",
     "start_time": "2026-01-19T15:58:13.919017Z"
    }
   },
   "outputs": [],
   "source": [
    "# —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ –≤ colab\n",
    "if colab:\n",
    "    !pip install rootutils -q\n",
    "    !pip install torchmetrics -q\n",
    "    !pip install torchinfo -q\n",
    "    !pip install lightning -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0a22da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T15:58:16.089856Z",
     "start_time": "2026-01-19T15:58:16.021716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working directory: /Users/alex/computer-vision\n"
     ]
    }
   ],
   "source": [
    "# –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ google –¥–∏—Å–∫–∞ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞\n",
    "# —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ `computer-vision`\n",
    "\n",
    "import os\n",
    "from rootutils import setup_root\n",
    "\n",
    "if colab:\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "    os.chdir(\"drive/MyDrive/computer-vision\")\n",
    "    root = setup_root(\".\", indicator=\"homeworks\", pythonpath=True)\n",
    "else:\n",
    "    root = setup_root(\".\", indicator=\"homeworks\", pythonpath=True)\n",
    "\n",
    "os.chdir(root)\n",
    "print(f\"working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f5566b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T15:58:18.013517Z",
     "start_time": "2026-01-19T15:58:17.952847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: /Users/alex/computer-vision/data\n"
     ]
    }
   ],
   "source": [
    "# —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "if colab:\n",
    "    DATA_DIR = Path(\"/content/data\")\n",
    "else:\n",
    "    DATA_DIR = root / \"data\"\n",
    "\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8dd3fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T15:58:19.065777Z",
     "start_time": "2026-01-19T15:58:19.039287Z"
    }
   },
   "outputs": [],
   "source": [
    "# –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"retina\"\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6e3944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T15:58:21.777463Z",
     "start_time": "2026-01-19T15:58:21.754408Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load tensorboard extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b7bf7",
   "metadata": {},
   "source": [
    "## **–ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏. –ú–µ—Ç–æ–¥—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f6f60",
   "metadata": {},
   "source": [
    "### **–ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏**\n",
    "\n",
    "**–ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏** (Fully Connected Neural Networks, FCNN).\n",
    "\n",
    "–î—Ä—É–≥–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ - **–º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–π –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω** (Multilayer Perceptron, MLP).\n",
    "\n",
    "**–ü—Ä–∏–º–µ—Ä –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–π —Å–µ—Ç–∏**\n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "        <img src=\"figs/02/fcnn.jpg\" width=\"600px\"/>\n",
    "    </figure>\n",
    "</center>\n",
    "\n",
    "- –£ —ç—Ç–æ–π —Å–µ—Ç–∏ –æ–¥–∏–Ω –≤—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π, –æ–¥–∏–Ω –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –∏ —Ç—Ä–∏ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è.\n",
    "\n",
    "- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ \n",
    "    $$\n",
    "        \\mathbf{w} = \\left\\{\n",
    "            \\boldsymbol{\\beta}_0,\\boldsymbol{\\Omega}_0,\n",
    "            \\boldsymbol{\\beta}_1,\\boldsymbol{\\Omega}_1,\n",
    "            \\boldsymbol{\\beta}_2,\\boldsymbol{\\Omega}_2,\n",
    "            \\boldsymbol{\\beta}_3,\\boldsymbol{\\Omega}_3\n",
    "        \\right\\}\n",
    "    $$\n",
    "    –ß–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ä–∞–≤–Ω–æ:\n",
    "    $$\n",
    "        (D_1\\cdot D_i + D_1) + (D_2\\cdot D_1 + D_2) + (D_3\\cdot D_2 + D_3) + (D_0\\cdot D_3 + D_0) = 43\n",
    "    $$\n",
    "\n",
    "- –í—ã—á–∏—Å–ª–µ–Ω–∏—è —Å–ª–æ–µ–≤ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏:\n",
    "    $$\n",
    "        \\mathbf{h}_1 = \\mathbf{a}\\left[\\boldsymbol{\\beta}_0 + \\mathbf{\\Omega}_0 \\mathbf{x}\\right]\n",
    "    $$\n",
    "    $$\n",
    "        \\mathbf{h}_2 = \\mathbf{a}\\left[\\boldsymbol{\\beta}_1 + \\mathbf{\\Omega}_1 \\mathbf{h}_1\\right]\n",
    "    $$\n",
    "    $$\n",
    "        \\mathbf{h}_3 = \\mathbf{a}\\left[\\boldsymbol{\\beta}_2 + \\mathbf{\\Omega}_2 \\mathbf{h}_2\\right]\n",
    "    $$\n",
    "    $$\n",
    "        \\mathbf{y} = \\boldsymbol{\\beta}_3 + \\mathbf{\\Omega}_3 \\mathbf{h}_3\n",
    "    $$\n",
    "\n",
    "    –≥–¥–µ $\\mathbf{a}$ - —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏, –æ–±—ã—á–Ω–æ —ç—Ç–æ $\\mathrm{ReLU}$ (Rectified Linear Unit):\n",
    "    <center>\n",
    "        <figure>\n",
    "            <img src=\"https://media.githubusercontent.com/media/alextanch/computer-vision/refs/heads/at/lesson2/notebooks/figs/02/relu.png\" width=\"200px\"/>\n",
    "        </figure>\n",
    "    </center>\n",
    "\n",
    "    $$\n",
    "        a[z] = \\mathrm{ReLU}[z] =\n",
    "        \\begin{cases}\n",
    "            0 & z < 0\\\\\n",
    "            z & z \\geqslant 0\n",
    "        \\end{cases}\n",
    "    $$\n",
    "\n",
    "- –°–µ—Ç—å –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è **–ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–π**, –ø–æ—Å–∫–æ–ª—å–∫—É –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç (node) —Å–≤—è–∑–∞–Ω —Å–æ –≤—Å–µ–º–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca713d",
   "metadata": {},
   "source": [
    "–î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ —Å–ª–æ—è –≤ PyTorch –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–ª–∞—Å—Å `torch.nn.Linear()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20547840",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T15:58:38.889352Z",
     "start_time": "2026-01-19T15:58:37.799194Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, Di=3, D1=4, D2=2, D3=3, Do=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin1 = nn.Linear(Di, D1)\n",
    "        self.lin2 = nn.Linear(D1, D2)\n",
    "        self.lin3 = nn.Linear(D2, D3)\n",
    "        self.lin4 = nn.Linear(D3, Do)\n",
    "\n",
    "        self.act = nn.ReLU() \n",
    "         \n",
    "    def forward(self, x):\n",
    "        h1 = self.act(self.lin1(x))\n",
    "        h2 = self.act(self.lin2(h1))\n",
    "        h3 = self.act(self.lin3(h2))\n",
    "        \n",
    "        y = self.lin4(h3)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64444c15",
   "metadata": {},
   "source": [
    "–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–±–æ—Ç—É —Å–µ—Ç–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee3aa3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T15:58:59.751810Z",
     "start_time": "2026-01-19T15:58:59.706534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([5, 3])\n",
      "\n",
      "x: tensor([[0.2295, 0.3219, 0.3251],\n",
      "        [0.1857, 0.5534, 0.8699],\n",
      "        [0.6706, 0.8455, 0.4662],\n",
      "        [0.6288, 0.4890, 0.5237],\n",
      "        [0.0253, 0.3506, 0.1110]])\n",
      "\n",
      "y.shape: torch.Size([5, 2])\n",
      "\n",
      "y: tensor([[0.6786, 0.2852],\n",
      "        [0.6786, 0.2852],\n",
      "        [0.6786, 0.2852],\n",
      "        [0.6786, 0.2852],\n",
      "        [0.6786, 0.2852]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# –º–æ–¥–µ–ª—å —Å–µ—Ç–∏\n",
    "model = Net()\n",
    "\n",
    "# –±–∞—Ç—á —Ä–∞–∑–º–µ—Ä–∞ 5 –∏–∑ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª\n",
    "x = torch.rand((5, 3))\n",
    "\n",
    "# forward pass\n",
    "y = model(x)\n",
    "\n",
    "print(f\"x.shape: {x.shape}\")\n",
    "print(f\"\\nx: {x}\")\n",
    "print(f\"\\ny.shape: {y.shape}\")\n",
    "print(f\"\\ny: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751c466",
   "metadata": {},
   "source": [
    "–í—ã–≤–µ–¥–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ —Å–µ—Ç–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be3dfac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T15:59:07.771534Z",
     "start_time": "2026-01-19T15:59:07.706841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Net                                      [5, 2]                    --\n",
      "‚îú‚îÄLinear: 1-1                            [5, 4]                    16\n",
      "‚îú‚îÄReLU: 1-2                              [5, 4]                    --\n",
      "‚îú‚îÄLinear: 1-3                            [5, 2]                    10\n",
      "‚îú‚îÄReLU: 1-4                              [5, 2]                    --\n",
      "‚îú‚îÄLinear: 1-5                            [5, 3]                    9\n",
      "‚îú‚îÄReLU: 1-6                              [5, 3]                    --\n",
      "‚îú‚îÄLinear: 1-7                            [5, 2]                    8\n",
      "==========================================================================================\n",
      "Total params: 43\n",
      "Trainable params: 43\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "print(torchinfo.summary(model, input_size=x.shape, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1177d6c",
   "metadata": {},
   "source": [
    "–ú–æ–∂–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å –±–æ–ª–µ–µ –∫–æ–º–ø–∞–∫—Ç–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é —Å –ø–æ–º–æ—â—å—é `torch.nn.Sequential`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8191bdd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T15:59:13.595232Z",
     "start_time": "2026-01-19T15:59:13.515386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Net                                      [5, 2]                    --\n",
      "‚îú‚îÄLinear: 1-1                            [5, 4]                    16\n",
      "‚îú‚îÄReLU: 1-2                              [5, 4]                    --\n",
      "‚îú‚îÄLinear: 1-3                            [5, 2]                    10\n",
      "‚îú‚îÄReLU: 1-4                              [5, 2]                    --\n",
      "‚îú‚îÄLinear: 1-5                            [5, 3]                    9\n",
      "‚îú‚îÄReLU: 1-6                              [5, 3]                    --\n",
      "‚îú‚îÄLinear: 1-7                            [5, 2]                    8\n",
      "==========================================================================================\n",
      "Total params: 43\n",
      "Trainable params: 43\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, Di=3, D1=4, D2=2, D3=3, Do=2):\n",
    "        super().__init__()\n",
    "\n",
    "        act = nn.ReLU()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(Di, D1),\n",
    "            act,\n",
    "            nn.Linear(D1, D2),\n",
    "            act,\n",
    "            nn.Linear(D2, D3),\n",
    "            act,\n",
    "            nn.Linear(D3, Do),\n",
    "        )\n",
    "         \n",
    "    def forward(self, x):\n",
    "        y = self.layers(x)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    model = Net()\n",
    "\n",
    "    print(torchinfo.summary(model, input_size=x.shape, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41dfcad",
   "metadata": {},
   "source": [
    "### **–ú–µ—Ç–æ–¥—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏**\n",
    "\n",
    "- **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –≤ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ**: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "    –ø–æ—Ç–µ—Ä—å –∑–∞–¥–∞–Ω–Ω—ã—Ö –≤ —è–≤–Ω–æ–º –≤–∏–¥–µ —á–ª–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º—É\n",
    "    –≤—ã–±–æ—Ä—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "\n",
    "- **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏**: –ª—é–±—ã–µ –º–µ—Ç–æ–¥—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–ª—É—á—à–∞—é—Ç –æ–±–æ–±—â–∞—é—â—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "–ù–∞–∏–±–æ–ª–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏:\n",
    "\n",
    "- –í—ã–±–æ—Ä –ø–æ–¥—Ö–æ–¥—è—â–µ–π –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏.\n",
    "- –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.\n",
    "- Learning rate schedulers.\n",
    "- –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å.\n",
    "- –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è.\n",
    "- –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è (early stopping).\n",
    "\n",
    "–ü—Ä–∏–º–µ–Ω–∏–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∏–∑ –º–µ—Ç–æ–¥–æ–≤ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffc6f4",
   "metadata": {},
   "source": [
    "### **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π Fashion-MNIST** \n",
    "\n",
    "–ù–∞ –ø—Ä–∏–º–µ—Ä–µ –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ Fashion-MNIST, —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∏–∑ –º–µ—Ç–æ–¥–æ–≤ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏.\n",
    "\n",
    "–î–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ PyTorch Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335114ae",
   "metadata": {},
   "source": [
    "#### **–î–∞–Ω–Ω—ã–µ Fasion-MNIST**\n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "        <img src=\"https://media.githubusercontent.com/media/alextanch/computer-vision/refs/heads/at/lesson2/notebooks/figs/02/fashion_mnist.jpg\" width=\"700px\"/>\n",
    "    </figure>\n",
    "</center>\n",
    "\n",
    "- –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: 28x28 –ø–∏–∫—Å–µ–ª–µ–π\n",
    "\n",
    "- –¶–≤–µ—Ç–æ–≤–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ: grayscale\n",
    "\n",
    "- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: 10 (–æ–¥–µ–∂–¥–∞)\n",
    "\n",
    "- –†–∞–∑–º–µ—Ä –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: 60 000 –æ–±—É—á–∞—é—â–∏—Ö –∏ 10 000 —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a3490b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T15:59:22.256884Z",
     "start_time": "2026-01-19T15:59:22.237717Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b63d310",
   "metadata": {},
   "source": [
    "–í torchvision –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö:\n",
    "\n",
    "https://docs.pytorch.org/vision/main/datasets.html#image-classification\n",
    "\n",
    "–µ—Å—Ç—å –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã Fashion-MNIST.\n",
    "\n",
    "–î–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –ø–æ–ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞—Ç—å—Å—è, –Ω–∞–ø–∏—à–µ–º —Å–≤–æ—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∫–ª–∞—Å—Å–∞ `torch.utils.data.Dataset` –¥–ª—è Fashion-MNIST.\n",
    "\n",
    "–ó–∞–≥—Ä—É–∑–∏–º –∏ —Ä–∞—Å–ø–∞–∫—É–µ–º Fashion-MNIST –¥–∞–Ω–Ω—ã–µ —Å Google Disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "754fead2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T15:59:29.841470Z",
     "start_time": "2026-01-19T15:59:29.691479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from src.utils import download_and_extract\n",
    "\n",
    "download_and_extract(\"1KpBql_Rpc1dtBSwFTT7UZdNLUoDde6YQ\", \"fashion-mnist.zip\", DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60951207",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:00:01.977037Z",
     "start_time": "2026-01-19T16:00:00.043645Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "class DataSet(Dataset):\n",
    "    def __init__(self, image_files, transform):\n",
    "        super().__init__()\n",
    "\n",
    "        self.files = image_files\n",
    "        self.labels = [int(f.parent.name) for f in self.files]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(self.files[index], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        x = self.transform(image)\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir, batch_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.test_dataset = DataSet(\n",
    "            list((data_dir / \"test\").glob(\"**/*.png\")), \n",
    "            T.Compose([\n",
    "                T.ToTensor()\n",
    "            ])\n",
    "        )\n",
    "    \n",
    "        files = list((data_dir / \"train\").glob(\"**/*.png\"))\n",
    "\n",
    "        train_files, val_files = random_split(\n",
    "            files,\n",
    "            [50_000, 10_000],\n",
    "            generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "\n",
    "        self.train_dataset = DataSet(\n",
    "            train_files, \n",
    "            T.Compose([\n",
    "                T.ToTensor()\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        self.val_dataset = DataSet(\n",
    "            val_files, \n",
    "            T.Compose([\n",
    "                T.ToTensor()\n",
    "            ])\n",
    "        )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        loader = DataLoader(\n",
    "            self.train_dataset, \n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0,\n",
    "            shuffle=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        return loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        loader = DataLoader(\n",
    "            self.val_dataset, \n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0,\n",
    "            shuffle=False,\n",
    "            drop_last=False\n",
    "        )\n",
    "        return loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        loader = DataLoader(\n",
    "            self.test_dataset, \n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0,\n",
    "            shuffle=False,\n",
    "            drop_last=False\n",
    "        )\n",
    "        return loader\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        loader = DataLoader(\n",
    "            self.test_dataset, \n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0,\n",
    "            shuffle=False,\n",
    "            drop_last=False\n",
    "        )\n",
    "        return loader\n",
    "    \n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "\n",
    "datamodule = DataModule(data_dir=DATA_DIR / \"fashion-mnist\", batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d63b9c68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:00:05.543894Z",
     "start_time": "2026-01-19T16:00:05.214132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "loader = datamodule.train_dataloader()\n",
    "dataset = loader.dataset\n",
    "\n",
    "x, y = next(iter(loader))\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b032378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:00:08.515032Z",
     "start_time": "2026-01-19T16:00:08.419101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 272,
       "width": 250
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "image = x.squeeze()[0]\n",
    "label = y[0].item()\n",
    "\n",
    "image = (255 * image).numpy().astype(np.uint8)\n",
    "class_name = class_names[label]\n",
    "\n",
    "# –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.title(f\"class name: {class_name}\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1fc4a75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:00:12.051892Z",
     "start_time": "2026-01-19T16:00:12.023255Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(28 * 28, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–∞–∑–º–µ—Ä \n",
    "        # B x 1 x 28 x 28 -> B x (28 * 28)\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        \n",
    "        y = self.layers(x)\n",
    "\n",
    "        return y\n",
    "    \n",
    "\n",
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(self, hidden_size, learning_rate):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = Net(hidden_size)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log(\"train/loss\", loss, on_step=False, on_epoch=True, prog_bar=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log(\"val/loss\", loss, on_step=False, on_epoch=True, prog_bar=False)\n",
    "        \n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n",
    "        x, _ = batch\n",
    "        return self(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # self.hparams available because we called self.save_hyperparameters()\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "model = Classifier(hidden_size=196, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9917ec15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:00:14.168153Z",
     "start_time": "2026-01-19T16:00:14.111554Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir = DATA_DIR / \"classifier\",                          \n",
    "    accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\",                    \n",
    "    devices=1,                                                                         \n",
    "    max_epochs=10,                                                                    \n",
    "    callbacks=[\n",
    "        #ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"), \n",
    "        LearningRateMonitor(\"epoch\")\n",
    "    ],                                     \n",
    "    enable_progress_bar=True\n",
    ")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a73d70c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:01:34.392836Z",
     "start_time": "2026-01-19T16:00:18.115200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type             | Params | Mode  | FLOPs\n",
      "-------------------------------------------------------------\n",
      "0 | net     | Net              | 155 K  | train | 0    \n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train | 0    \n",
      "-------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.623     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e11c19d829847e387f64757277b65d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb503fd8cfa14aa8af7503a6a233a09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11c019be845470bb4388b78491a46c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf0503223b2413580dfea9f5f887e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ff700d1223467aa9f3317015c0c726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c05421a38834635bd1410369a4921f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baae47593514373986a02187468effc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f542d296ebe743b580bb6debb8c142fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da4ed780b85480c9d1f4c0d01d9b7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc57c7f212e4ff0afe8426e149d1e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcab61a96c1c404db1cce19ab4441b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9434aeef372c4431bff6d9d27d1c7d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens tensorboard in notebook. Adjust the path to your CHECKPOINT_PATH!\n",
    "if colab:\n",
    "    %tensorboard --logdir data/classifier/lightning_logs/version_0\n",
    "else:\n",
    "    !tensorboard --logdir data/classifier/lightning_logs/version_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec003db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1. Define transformations: Convert images to PyTorch tensors\n",
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "             \n",
    "# 2. Load the Fashion-MNIST datasets (downloads if not present)\n",
    "train_dataset = FashionMNIST(\n",
    "    root=DATA_DIR, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = FashionMNIST(\n",
    "    root=DATA_DIR, \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05de898",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –æ–¥–∏–Ω –∏–∑ —Å—ç–º–ø–ª–æ–≤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e3cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x - tensor\n",
    "# y - int\n",
    "x, y = train_dataset[2026]\n",
    "\n",
    "class_name = class_names[y]\n",
    "\n",
    "print(f\"x.shape: {x.shape}\")\n",
    "print(f\"label: {y}\")\n",
    "print(f\"class name: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207c92c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# –¥–µ-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "image = (255 * x.squeeze()).numpy().astype(np.uint8)\n",
    "\n",
    "# –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.title(f\"class name: {class_name}\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d3ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae33e7a3",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4353166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet(DATA_DIR / \"fashion-mnist/train\")\n",
    "test_dataset = DataSet(DATA_DIR / \"fashion-mnist/test\")\n",
    "\n",
    "# —á–∏—Å–ª–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö\n",
    "print(f\"dataset size: {len(dataset)}\")\n",
    "print(f\"test_dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84333b",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –æ–¥–∏–Ω –∏–∑ —Å—ç–º–ø–ª–æ–≤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ac9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x - numpy –º–∞—Å—Å–∏–≤\n",
    "# y - int\n",
    "x, y = dataset[2026]\n",
    "\n",
    "# –∏–º—è –∫–ª–∞—Å—Å–∞\n",
    "class_name = class_names[y]\n",
    "\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y: {y}\")\n",
    "\n",
    "# –¥–µ-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "image = (255 * x[0]).astype(np.uint8)\n",
    "\n",
    "# –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.title(f\"class: {class_name}\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb303fa9",
   "metadata": {},
   "source": [
    "–†–∞–∑–¥–µ–ª–∏–º `dataset` –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset,\n",
    "    [50_000, 10_000]\n",
    ")\n",
    "\n",
    "print(f\"train_dataset size: {len(train_dataset)}\")\n",
    "print(f\"val_dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df337bf6",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –±–∞—Ç—á–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,   # –¥–∞—Ç–∞—Å–µ—Ç\n",
    "    batch_size=1024, # —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞\n",
    "    num_workers=0,   # —á–∏—Å–ª–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –±–∞—Ç—á–µ–π\n",
    "    shuffle=True,    # –ø–µ—Ä–µ–º–µ—à–∏–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –≤ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏\n",
    "    drop_last=True   # –≤—ã–±—Ä–∞—Å—ã–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –Ω–µ–ø–æ–ª–Ω—ã–π –±–∞—Ç—á –≤ —ç–ø–æ—Ö–µ\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1024,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# —á–∏—Å–ª–æ –±–∞—Ç—á–µ–π\n",
    "print(f\"train_loader size: {len(train_loader)}\")\n",
    "print(f\"val_loader size: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212234f",
   "metadata": {},
   "source": [
    "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–¥–∏–Ω –±–∞—Ç—á –∏–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b3e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–æ–ª–∂–µ–Ω\n",
    "# –∏–º–µ—Ç—å –≤–∏–¥ B x C x H x W\n",
    "# (—Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞) x (—á–∏—Å–ª–æ —Ü–≤–µ—Ç–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤) x (–≤—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è) x (—à–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)\n",
    "\n",
    "# –≤—ã–±–æ—Ä–∫–∞ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –±–∞—Ç—á–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "# x, y - —ç—Ç–æ —Ç–µ–Ω–∑–æ—Ä—ã\n",
    "x, y = next(iter(train_loader))\n",
    "\n",
    "# –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω—É–∂–Ω–æ–º—É —Ç–∏–ø—É –¥–∞–Ω–Ω—ã—Ö\n",
    "x = x.float()\n",
    "y = y.long()\n",
    "\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y shape: {y.shape}\\n\")\n",
    "\n",
    "print(f\"x.min(): {x.min()}\")\n",
    "print(f\"x.max(): {x.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ccbac",
   "metadata": {},
   "source": [
    "#### **–ú–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞**\n",
    "\n",
    "–°–æ–∑–¥–∞–¥–∏–º –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –æ–¥–Ω–∏–º —Å–∫—Ä—ã—Ç—ã–º —Å–ª–æ–µ–º:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4559ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, D):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(28 * 28, D),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(D, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–∞–∑–º–µ—Ä \n",
    "        # B x 1 x 28 x 28 -> B x (28 * 28)\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        \n",
    "        y = self.layers(x)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a036718",
   "metadata": {},
   "source": [
    "–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —Å–µ—Ç–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(D=196)\n",
    "\n",
    "x, y = next(iter(val_loader))\n",
    "\n",
    "y_hat = model(x)\n",
    "\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"y_hat shape: {y_hat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a58a0e8",
   "metadata": {},
   "source": [
    "–í—ã–≤–µ–¥–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee645d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torchinfo.summary(model, input_size=x.shape, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08d7ee2",
   "metadata": {},
   "source": [
    "#### **–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –∏ –º–µ—Ç—Ä–∏–∫–∞**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892b81a",
   "metadata": {},
   "source": [
    "–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –¥–ª—è –∑–∞–¥–∞—á–∏ –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ - —Å—Ä–µ–¥–Ω—è—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è –Ω–∞ –±–∞—Ç—á–µ (Cross Entropy):\n",
    "$$\n",
    "    \\mathbf{CE} = \n",
    "    -\\frac{1}{|\\mathcal{I}_t|}\n",
    "    \\sum_{i\\in\\mathcal{I}_t}\\mathbf{p}_i\\cdot\\ln \\widehat{\\mathbf{p}}_i\n",
    "$$\n",
    "–≥–¥–µ $\\mathbf{p}_i$ - one-hot –≤–µ–∫—Ç–æ—Ä –∏—Å—Ç–∏–Ω–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –Ω–æ–º–µ—Ä–æ–º $i$:\n",
    "$$\n",
    "   \\mathbf{p}_i = (0\\,,0\\,,\\ldots\\,,1\\,,0\\,,\\ldots\\,,0)\n",
    "$$ \n",
    "$\\widehat{\\mathbf{p}}_i$ - –≤–µ–∫—Ç–æ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—å—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –Ω–æ–º–µ—Ä–æ–º $i$:\n",
    "$$\n",
    "    \\widehat{\\mathbf{p}}_i = \\mathrm{softmax}[\\widehat{\\mathbf{y}}_i] = \n",
    "    \\frac{\\exp[\\widehat{\\mathbf{y}}_i]}{\\sum\\limits_j \\exp[\\widehat{y}_{ij}]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5668e73",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç $\\left\\{\\mathbf{y}_i\\right\\}_{i\\in\\mathcal{I}_t}$.\n",
    "\n",
    "–ú–æ–¥–µ–ª—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç $\\left\\{\\widehat{\\mathbf{y}}_i\\right\\}_{i\\in\\mathcal{I}_t}$.\n",
    "\n",
    "–í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥—è—Ç –≤ –∫–ª–∞—Å—Å–µ `torch.nn.CrossEntropyLoss()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feca23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "\n",
    "y_hat = model(x.float())\n",
    "\n",
    "# –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ loss —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—é `y_hat` –∏ —Ä–µ–∞–ª—å–Ω–æ–º—É `y`\n",
    "# –≤—ã—á–∏—Å–ª–µ–Ω–∏—è softmax –∏ one-hot encoding `y` —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ `loss_fn` \n",
    "loss = loss_fn(y_hat, y)\n",
    "\n",
    "print(f\"loss value = {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e6448a",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –≤–æ–∑—å–º–µ–º SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ea73b",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–æ–∑—å–º–µ–º —Å—Ä–µ–¥–Ω—é—é —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21aa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "# –≤—ã—á–∏—Å–ª—è–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É\n",
    "metric = MulticlassAccuracy(num_classes=10, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692fda0d",
   "metadata": {},
   "source": [
    "–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫—É –∫–∞—á–µ—Å—Ç–≤–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0dc29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∏—Ç–µ—Ä–∞—Ç–æ—Ä –ø–æ –¥–∞–Ω–Ω—ã–º\n",
    "iterator = iter(val_loader)\n",
    "\n",
    "# –ø–æ–ª—É—á–∏–º –ø–µ—Ä–≤—ã–π –±–∞—Ç—á \n",
    "x, y = next(iterator)\n",
    "y_hat = model(x.float())\n",
    "\n",
    "# –¥–æ–±–∞–≤–∏–º –≤ –º–µ—Ç—Ä–∏–∫—É\n",
    "metric.update(y_hat, y.long())\n",
    "\n",
    "# –ø–æ–ª—É—á–∏–º —Å–ª–µ–¥—É—é—â–∏–π –±–∞—Ç—á\n",
    "x, y = next(iterator)\n",
    "y_hat = model(x.float())\n",
    "\n",
    "# –¥–æ–±–∞–≤–∏–º –≤ –º–µ—Ç—Ä–∏–∫—É\n",
    "metric.update(y_hat, y.long())\n",
    "\n",
    "# –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É\n",
    "accuracy = metric.compute()\n",
    "\n",
    "# —Å—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º\n",
    "mean_accuracy = accuracy.mean()\n",
    "\n",
    "print(f\"class accuracy: {accuracy}\")\n",
    "print(f\"mean accuracy: {mean_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5727370e",
   "metadata": {},
   "source": [
    "#### **–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏**\n",
    "\n",
    "–°–æ–±–µ—Ä–µ–º –≤—Å–µ –≤–º–µ—Å—Ç–µ –∏ –Ω–∞–ø–∏—à–µ–º –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –ø–æ —ç–ø–æ—Ö–∞–º:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f0f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from torchmetrics.aggregation import MeanMetric\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "from src.utils import set_seed\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    seed = 0xC0FFEE\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_workers = 0\n",
    "    # –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    epochs = 10\n",
    "    learning_rate = 0.1\n",
    "    batch_size = 1000\n",
    "    D = 196\n",
    "    \n",
    "cfg = Config()\n",
    "\n",
    "# –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "# –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=cfg.num_workers\n",
    ")\n",
    "\n",
    "# –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=cfg.num_workers\n",
    ")\n",
    "\n",
    "# –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞\n",
    "model = Classifier(D=cfg.D)\n",
    "model = model.to(cfg.device)\n",
    "\n",
    "# –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä \n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=cfg.learning_rate)\n",
    "\n",
    "# —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è\n",
    "plot = PlotLosses(figsize=(12, 3))\n",
    "\n",
    "# –ª—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "best_metric = 0\n",
    "\n",
    "for epoch in range(cfg.epochs):\n",
    "    # –≠–ü–û–•–ê –û–ë–£–ß–ï–ù–ò–Ø –ú–û–î–ï–õ–ò\n",
    "\n",
    "    # –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–µ–¥–µ–º –≤ —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è\n",
    "    model.train()\n",
    "\n",
    "    # –∑–Ω–∞—á–µ–Ω–∏—è loss —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–∞ –±–∞—Ç—á–∞—Ö –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏\n",
    "    batch_losses = torch.empty(0)\n",
    "\n",
    "    metric = MulticlassAccuracy(num_classes=10, average=None)\n",
    "\n",
    "    # –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏\n",
    "    mean_metric = MeanMetric()\n",
    "\n",
    "    # –≤—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –±–∞—Ç—á–∏ –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    for x, y in train_loader:\n",
    "        x = x.float().to(cfg.device)\n",
    "        y = y.long().to(cfg.device)\n",
    "\n",
    "        # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        y_hat = model(x)\n",
    "\n",
    "        # –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ loss —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—é `y_hat` –∏ —Ä–µ–∞–ª—å–Ω–æ–º—É `y`\n",
    "        loss = loss_fn(y_hat, y)\n",
    "\n",
    "        # –æ–±–Ω—É–ª–∏–º –≤—Å–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø–µ—Ä–µ–¥ –∏—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º–∏\n",
    "        # —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ gradient accumulation\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö loss —Ñ—É–Ω–∫—Ü–∏—è –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º\n",
    "        # c –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–∞ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏ (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏\n",
    "        optimizer.step()\n",
    "\n",
    "        mean_metric.update(loss.detach().cpu())\n",
    "        metric.update(y_hat.detach().cpu(), y.cpu())\n",
    "\n",
    "    # —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –≤ —ç–ø–æ—Ö–µ –æ–±—É—á–µ–Ω–∏—è\n",
    "    train_epoch_loss = mean_metric.compute()\n",
    "    \n",
    "    # —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ —ç–ø–æ—Ö–µ –æ–±—É—á–µ–Ω–∏—è\n",
    "    train_epoch_metric = metric.compute().mean()\n",
    "    \n",
    "    # –≠–ü–û–•–ê –í–ê–õ–ò–î–ê–¶–ò–ò –ú–û–î–ï–õ–ò\n",
    "\n",
    "    # –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–µ–¥–µ–º –≤ —Ä–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "    model.eval()\n",
    "\n",
    "    batch_losses = torch.empty(0)\n",
    "\n",
    "    metric = MulticlassAccuracy(num_classes=10, average=None)\n",
    "    mean_metric = MeanMetric()\n",
    "\n",
    "    for x, y in val_loader:\n",
    "        x = x.float().to(cfg.device)\n",
    "        y = y.long().to(cfg.device)\n",
    "\n",
    "        # —ç—Ç–æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(x)\n",
    "        \n",
    "        loss = loss_fn(y_hat, y)\n",
    "\n",
    "        mean_metric.update(loss.cpu())\n",
    "        metric.update(y_hat.cpu(), y.cpu())\n",
    "\n",
    "    # —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –≤ —ç–ø–æ—Ö–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "    val_epoch_loss = mean_metric.compute()\n",
    "\n",
    "    # —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ —ç–ø–æ—Ö–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "    val_epoch_metric = metric.compute().mean()\n",
    "\n",
    "    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–µ—Ç—Ä–∏–∫–∞ —É–ª—É—á—à–∏–ª–∞—Å—å\n",
    "    if best_metric < val_epoch_metric:\n",
    "        best_metric = val_epoch_metric\n",
    "        torch.save(model.state_dict(), DATA_DIR / \"classifier.pth\")\n",
    "\n",
    "    # –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è\n",
    "    plot.update({\n",
    "        \"loss\": train_epoch_loss,\n",
    "        \"val_loss\": val_epoch_loss,\n",
    "        \"accuracy\": train_epoch_metric,\n",
    "        \"val_accuracy\": val_epoch_metric\n",
    "    })\n",
    "\n",
    "    plot.send()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422c5c6",
   "metadata": {},
   "source": [
    "#### **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏**\n",
    "\n",
    "–ó–∞–≥—Ä—É–∑–∏–º –≤–µ—Å–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bfb64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(DATA_DIR / \"classifier.pth\", weights_only=True)\n",
    "\n",
    "model = Classifier(cfg.D)\n",
    "model.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc0f9e7",
   "metadata": {},
   "source": [
    "–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ CPU –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1000,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "model.eval()\n",
    "\n",
    "metric = MulticlassAccuracy(num_classes=10, average=None)\n",
    "\n",
    "# –ø–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ –±–∞—Ç—á–∏ –∏–∑ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "for x, y in test_loader:\n",
    "    x = x.float()\n",
    "    y = y.long()\n",
    "\n",
    "    # –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏, –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏\n",
    "    # —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `torch.inference_mode()` –∫–æ–Ω—Ç–µ–∫—Å—Ç\n",
    "    with torch.inference_mode():\n",
    "        y_hat = model(x)\n",
    "\n",
    "    metric.update(y_hat, y)\n",
    "\n",
    "class_accuracy = metric.compute()\n",
    "mean_accuracy = class_accuracy.mean()\n",
    "\n",
    "for label, accuracy in enumerate(class_accuracy):\n",
    "    name = class_names[label]\n",
    "    print(f\"{name:>15}: {100 * accuracy.item():.2f} %\")\n",
    "\n",
    "print(f\"\\nmean_accuracy: {100 * mean_accuracy.item():.2f} %\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a3b8f9",
   "metadata": {},
   "source": [
    "–í–æ–∑—å–º–µ–º –æ–¥–Ω–æ —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29212cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = test_dataset[102]\n",
    "\n",
    "image = (255 * x[0]).astype(np.uint8)\n",
    "name = class_names[y]\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.title(f\"Class: {name}\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43776a7",
   "metadata": {},
   "source": [
    "–∏ —Å–¥–µ–ª–∞–µ–º –Ω–∞ –Ω–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑ 28 x 28 numpy array\n",
    "# –≤ 1 x 1 x 28 x 28 pytorch tensor\n",
    "x = torch.from_numpy(image)\n",
    "x = x.unsqueeze(0).unsqueeze(1)\n",
    "x = x.float() / 255\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y_hat = model(x)\n",
    "\n",
    "# –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞ - \n",
    "# —ç—Ç–æ –∏–Ω–¥–µ–∫—Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤—ã—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏\n",
    "pred_label = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "# –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑ —Ç–µ–Ω–∑–æ—Ä–∞ –≤ —á–∏—Å–ª–æ\n",
    "pred_label = pred_label.item()\n",
    "\n",
    "# –∏–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "pred_class = class_names[pred_label]\n",
    "\n",
    "print(f\"Predicted class: {pred_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d36fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
